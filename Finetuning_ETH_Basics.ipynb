{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"182Jhr9WjQ9M0LJSlqbpfgEkplKHWYZHO","timestamp":1729322838348},{"file_id":"1lDTx1jSBTDnTdJmzQfJ0NI0gIb0JtM9x","timestamp":1729068787185},{"file_id":"1wRfrgrQoGDdN-M22eeTIHYkT1LKb0VNN","timestamp":1725776516412}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e844840cdac74e3388db1028f49b23b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1eb10f8e58c4e32aec33a45547e2837","IPY_MODEL_f56ba7096aa74006ba862e3a2f2edcff","IPY_MODEL_4d228e64f1b2419ead446f187c900a62"],"layout":"IPY_MODEL_9b3e743a92d944ceb9af6acbcaf6fee9"}},"f1eb10f8e58c4e32aec33a45547e2837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43134d41cba24998bfa4fd0c34689d73","placeholder":"​","style":"IPY_MODEL_e157da152a6c4f119dfa5be3501abb5a","value":"Evaluating: 100%"}},"f56ba7096aa74006ba862e3a2f2edcff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_407516a969cc452abf1b1e8d45f594c9","max":80,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d4ca89797df42e4aabcbe4075e200d9","value":80}},"4d228e64f1b2419ead446f187c900a62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f64f55d6b92447cbafe9e6e3cc42019","placeholder":"​","style":"IPY_MODEL_63c23240314d42c2a69fcd0b0ed8f2e4","value":" 80/80 [01:35&lt;00:00,  4.54s/it]"}},"9b3e743a92d944ceb9af6acbcaf6fee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43134d41cba24998bfa4fd0c34689d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e157da152a6c4f119dfa5be3501abb5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"407516a969cc452abf1b1e8d45f594c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d4ca89797df42e4aabcbe4075e200d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f64f55d6b92447cbafe9e6e3cc42019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63c23240314d42c2a69fcd0b0ed8f2e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["- Popular and efficient finetuning techniques can be found [here](https://huggingface.co/docs/peft/en/index) and may use [Low Rank Adaptation](https://github.com/microsoft/LoRA).  \n","- Furthermore a variety of datasets for finetuning can be found [here](https://huggingface.co/datasets).\n","- A comparison of LLMs based on human feedback can be found at https://lmarena.ai/?leaderboard ."],"metadata":{"id":"dy1FTvouoH_F"}},{"cell_type":"markdown","source":["[Getting started with LLM fine-tuning on Azure](https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning)"],"metadata":{"id":"RiiqoNhykggJ"}},{"cell_type":"markdown","source":["Demonstration:\n","[Fine Tuning GPT-3.5-Turbo](https://github.com/run-llama/llama_index/blob/main/experimental/openai_fine_tuning/openai_fine_tuning.ipynb)\n","\n","In this notebook, we walk through an example of fine-tuning gpt-3.5-turbo.\n","\n","Specifically, we attempt to distill GPT-4's knowledge, by generating training data with GPT-4 to then fine-tune GPT-3.5.\n","\n","All training data is generated using two different sections of our index data, creating both a training and evalution set.\n","\n","We then finetune with our [OpenAIFinetuneEngine](https://platform.openai.com/docs/guides/fine-tuning) wrapper abstraction.\n","\n","Evaluation is done using the ragas library, which we will detail later on."],"metadata":{"id":"m1Fz1kxymVo2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SiJ5K91JV6SR","executionInfo":{"status":"ok","timestamp":1729070144521,"user_tz":-180,"elapsed":54023,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"3f2039ef-0386-48b0-c9b5-48e968ec2ce9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index-finetuning\n","  Downloading llama_index_finetuning-0.2.1-py3-none-any.whl.metadata (992 bytes)\n","Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-finetuning)\n","  Downloading llama_index_core-0.11.18-py3-none-any.whl.metadata (2.4 kB)\n","Collecting llama-index-embeddings-adapter<0.3.0,>=0.2.0 (from llama-index-finetuning)\n","  Downloading llama_index_embeddings_adapter-0.2.2-py3-none-any.whl.metadata (688 bytes)\n","Collecting llama-index-llms-azure-openai<0.3.0,>=0.2.0 (from llama-index-finetuning)\n","  Downloading llama_index_llms_azure_openai-0.2.2-py3-none-any.whl.metadata (4.0 kB)\n","Collecting llama-index-llms-mistralai<0.3.0,>=0.2.0 (from llama-index-finetuning)\n","  Downloading llama_index_llms_mistralai-0.2.6-py3-none-any.whl.metadata (3.5 kB)\n","Collecting llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0 (from llama-index-finetuning)\n","  Downloading llama_index_postprocessor_cohere_rerank-0.2.1-py3-none-any.whl.metadata (723 bytes)\n","Collecting sentence-transformers>=2.3.0 (from llama-index-finetuning)\n","  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (6.0.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (3.10.10)\n","Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.2.14)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2024.6.1)\n","Collecting httpx (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (3.4)\n","Collecting nltk>3.8.1 (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.26.4)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (10.4.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2.9.2)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (4.12.2)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.16.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning) (2.4.1+cu121)\n","Collecting azure-identity<2.0.0,>=1.15.0 (from llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index-llms-openai<0.3.0,>=0.2.1 (from llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading llama_index_llms_openai-0.2.14-py3-none-any.whl.metadata (3.3 kB)\n","Collecting mistralai>=1.0.0 (from llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading mistralai-1.1.0-py3-none-any.whl.metadata (23 kB)\n","Collecting cohere<6.0.0,>=5.1.1 (from llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading cohere-5.11.0-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning) (4.44.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.3.0->llama-index-finetuning) (0.24.7)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (4.0.3)\n","Collecting azure-core>=1.31.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading azure_core-1.31.0-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning) (43.0.1)\n","Collecting msal>=1.30.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading msal-1.31.0-py3-none-any.whl.metadata (11 kB)\n","Collecting msal-extensions>=1.2.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n","Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading boto3-1.35.41-py3-none-any.whl.metadata (6.7 kB)\n","Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","Collecting httpx-sse==0.4.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.23.4)\n","Collecting sagemaker<3.0.0,>=2.232.1 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading sagemaker-2.232.2-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.19.1)\n","Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2024.8.30)\n","Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.3.0->llama-index-finetuning) (3.16.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.3.0->llama-index-finetuning) (24.1)\n","Collecting openai<2.0.0,>=1.40.0 (from llama-index-llms-openai<0.3.0,>=0.2.1->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from mistralai>=1.0.0->llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning) (0.2.0)\n","Collecting jsonpath-python<2.0.0,>=1.0.6 (from mistralai>=1.0.0->llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from mistralai>=1.0.0->llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil==2.8.2->mistralai>=1.0.0->llama-index-llms-mistralai<0.3.0,>=0.2.0->llama-index-finetuning) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2024.9.11)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (0.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (2.2.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (3.1.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning) (3.1.4)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.3.0->llama-index-finetuning) (0.4.5)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.3.0->llama-index-finetuning) (3.5.0)\n","Collecting botocore<1.36.0,>=1.35.41 (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading botocore-1.35.41-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning) (1.17.1)\n","Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning) (2.9.0)\n","Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.3.0,>=0.2.1->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning) (1.7.0)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.3.0,>=0.2.1->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (1.2.2)\n","Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning)\n","  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.2.1)\n","Collecting docker (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.2.0)\n","Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (4.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.2.2)\n","Collecting pathos (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading pathos-0.3.3-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (4.3.6)\n","Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.20.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (5.9.5)\n","Collecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading sagemaker_core-1.0.10-py3-none-any.whl.metadata (4.9 kB)\n","Collecting sagemaker-mlflow (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting schema (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n","Collecting smdebug-rulesconfig==1.0.1 (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n","Requirement already satisfied: tblib<4,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.0.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-finetuning) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->llama-index-embeddings-adapter<0.3.0,>=0.2.0->llama-index-finetuning) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-finetuning) (2.22)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.20.2)\n","Requirement already satisfied: rich<14.0.0,>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (13.9.2)\n","Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.20.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2024.2)\n","Collecting ppft>=1.7.6.9 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading ppft-1.7.6.9-py3-none-any.whl.metadata (12 kB)\n","Collecting dill>=0.3.9 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Collecting pox>=0.3.5 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading pox-0.3.5-py3-none-any.whl.metadata (8.0 kB)\n","Collecting multiprocess>=0.70.17 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Collecting mlflow>=2.8 (from sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\n","Collecting mlflow-skinny==2.17.0 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.2.5)\n","Collecting alembic!=1.10.0,<2 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.7)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.7.1)\n","Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (16.1.0)\n","Collecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (5.5.0)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading databricks_sdk-0.34.0-py3-none-any.whl.metadata (37 kB)\n","Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (1.16.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (1.16.0)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.5.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.18.0)\n","Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.0.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.2.0)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Collecting aniso8601<10,>=8 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (3.1.4)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (2.27.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (71.0.4)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.37b0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (4.9)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.3.0,>=0.2.0->llama-index-finetuning) (0.6.1)\n","Downloading llama_index_finetuning-0.2.1-py3-none-any.whl (30 kB)\n","Downloading llama_index_core-0.11.18-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_embeddings_adapter-0.2.2-py3-none-any.whl (4.5 kB)\n","Downloading llama_index_llms_azure_openai-0.2.2-py3-none-any.whl (6.3 kB)\n","Downloading llama_index_llms_mistralai-0.2.6-py3-none-any.whl (6.8 kB)\n","Downloading llama_index_postprocessor_cohere_rerank-0.2.1-py3-none-any.whl (2.9 kB)\n","Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cohere-5.11.0-py3-none-any.whl (249 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_llms_openai-0.2.14-py3-none-any.whl (13 kB)\n","Downloading mistralai-1.1.0-py3-none-any.whl (229 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading azure_core-1.31.0-py3-none-any.whl (197 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/197.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.35.41-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msal-1.31.0-py3-none-any.whl (113 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n","Downloading sagemaker-2.232.2-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n","Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n","Downloading botocore-1.35.41-py3-none-any.whl (12.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n","Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sagemaker_core-1.0.10-py3-none-any.whl (388 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.4/388.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathos-0.3.3-py3-none-any.whl (82 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\n","Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n","Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow-2.17.0-py3-none-any.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pox-0.3.5-py3-none-any.whl (29 kB)\n","Downloading ppft-1.7.6.9-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading databricks_sdk-0.34.0-py3-none-any.whl (565 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: schema, dirtyjson, aniso8601, types-requests, tenacity, smmap, smdebug-rulesconfig, ppft, pox, portalocker, parameterized, nltk, mypy-extensions, mock, marshmallow, Mako, jsonpath-python, jmespath, jiter, importlib-metadata, httpx-sse, h11, gunicorn, graphql-core, fastavro, dill, attrs, typing-inspect, tiktoken, multiprocess, httpcore, graphql-relay, gitdb, docker, botocore, azure-core, alembic, s3transfer, pathos, httpx, graphene, gitpython, dataclasses-json, databricks-sdk, openai, msal, mlflow-skinny, mistralai, llama-index-core, boto3, sentence-transformers, sagemaker-core, msal-extensions, mlflow, llama-index-llms-openai, llama-index-llms-mistralai, llama-index-embeddings-adapter, sagemaker-mlflow, azure-identity, sagemaker, llama-index-llms-azure-openai, cohere, llama-index-postprocessor-cohere-rerank, llama-index-finetuning\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.8.1\n","    Uninstalling nltk-3.8.1:\n","      Successfully uninstalled nltk-3.8.1\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.5.0\n","    Uninstalling importlib_metadata-8.5.0:\n","      Successfully uninstalled importlib_metadata-8.5.0\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 24.2.0\n","    Uninstalling attrs-24.2.0:\n","      Successfully uninstalled attrs-24.2.0\n","Successfully installed Mako-1.3.5 alembic-1.13.3 aniso8601-9.0.1 attrs-23.2.0 azure-core-1.31.0 azure-identity-1.19.0 boto3-1.35.41 botocore-1.35.41 cohere-5.11.0 databricks-sdk-0.34.0 dataclasses-json-0.6.7 dill-0.3.9 dirtyjson-1.0.8 docker-7.1.0 fastavro-1.9.7 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 importlib-metadata-6.11.0 jiter-0.6.1 jmespath-1.0.1 jsonpath-python-1.0.6 llama-index-core-0.11.18 llama-index-embeddings-adapter-0.2.2 llama-index-finetuning-0.2.1 llama-index-llms-azure-openai-0.2.2 llama-index-llms-mistralai-0.2.6 llama-index-llms-openai-0.2.14 llama-index-postprocessor-cohere-rerank-0.2.1 marshmallow-3.22.0 mistralai-1.1.0 mlflow-2.17.0 mlflow-skinny-2.17.0 mock-4.0.3 msal-1.31.0 msal-extensions-1.2.0 multiprocess-0.70.17 mypy-extensions-1.0.0 nltk-3.9.1 openai-1.51.2 parameterized-0.9.0 pathos-0.3.3 portalocker-2.10.1 pox-0.3.5 ppft-1.7.6.9 s3transfer-0.10.3 sagemaker-2.232.2 sagemaker-core-1.0.10 sagemaker-mlflow-0.1.0 schema-0.7.7 sentence-transformers-3.2.0 smdebug-rulesconfig-1.0.1 smmap-5.0.1 tenacity-8.5.0 tiktoken-0.8.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0\n","Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.10/dist-packages (0.2.14)\n","Requirement already satisfied: llama-index-core<0.12.0,>=0.11.7 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (0.11.18)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (1.51.2)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.10.10)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.2)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.9.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.26.4)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (10.4.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.9.2)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.5.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.8.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.12.2)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.7.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.0.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.11)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.2.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.1.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.22.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.2.0)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement llama-index-finetuning-callbacks (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for llama-index-finetuning-callbacks\u001b[0m\u001b[31m\n","\u001b[0mCollecting llama-index-readers-file\n","  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.12.3)\n","Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.11.18)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (2.2.2)\n","Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file)\n","  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n","Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n","  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.0.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10.10)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.27.2)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.4)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.9.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.26.4)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (10.4.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.9.2)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.5.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.8.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.12.2)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.0.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.9.11)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.23.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.1.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.22.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.14.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (24.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.2)\n","Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n","Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Installing collected packages: striprtf, pypdf, llama-index-readers-file\n","Successfully installed llama-index-readers-file-0.2.2 pypdf-4.3.1 striprtf-0.0.26\n","Collecting llama-index-program-openai\n","  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n","Collecting llama-index-agent-openai<0.4.0,>=0.3.0 (from llama-index-program-openai)\n","  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n","Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-program-openai) (0.11.18)\n","Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-program-openai) (0.2.14)\n","Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index-program-openai) (1.51.2)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (6.0.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.10.10)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2024.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.27.2)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.4)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.9.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.26.4)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (10.4.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2.9.2)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (8.5.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.8.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (4.12.2)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.16.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (4.0.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2024.9.11)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index-program-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index-program-openai) (1.7.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index-program-openai) (0.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index-program-openai) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.0.6)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (2.2.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.1.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (3.22.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index-program-openai) (1.2.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (24.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-program-openai) (0.2.0)\n","Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n","Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n","Installing collected packages: llama-index-agent-openai, llama-index-program-openai\n","Successfully installed llama-index-agent-openai-0.3.4 llama-index-program-openai-0.2.0\n"]}],"source":["%pip install llama-index-finetuning\n","%pip install llama-index-llms-openai\n","%pip install llama-index-finetuning-callbacks\n","%pip install llama-index-readers-file\n","%pip install llama-index-program-openai"]},{"cell_type":"code","source":["!pip show llama-index-finetuning\n","!pip show llama-index-finetuning-callbacks\n","!pip show llama-index-llms-openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBxrVwEytF4N","executionInfo":{"status":"ok","timestamp":1729070153479,"user_tz":-180,"elapsed":9498,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"fa9ee137-c32a-4f7b-8f3e-da4e0cd9cc9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: llama-index-finetuning\n","Version: 0.2.1\n","Summary: llama-index finetuning\n","Home-page: \n","Author: Your Name\n","Author-email: you@example.com\n","License: MIT\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: llama-index-core, llama-index-embeddings-adapter, llama-index-llms-azure-openai, llama-index-llms-mistralai, llama-index-postprocessor-cohere-rerank, sentence-transformers\n","Required-by: \n","\u001b[33mWARNING: Package(s) not found: llama-index-finetuning-callbacks\u001b[0m\u001b[33m\n","\u001b[0mName: llama-index-llms-openai\n","Version: 0.2.14\n","Summary: llama-index llms openai integration\n","Home-page: \n","Author: llama-index\n","Author-email: \n","License: MIT\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: llama-index-core, openai\n","Required-by: llama-index-agent-openai, llama-index-llms-azure-openai, llama-index-program-openai\n"]}]},{"cell_type":"code","source":["!pip show llama-index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTXHovWTtuQR","executionInfo":{"status":"ok","timestamp":1729070154271,"user_tz":-180,"elapsed":994,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"70b43a8a-d2ed-4cac-e2ec-b7f8ac9232f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Package(s) not found: llama-index\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","import openai"],"metadata":{"id":"fx7x5kw5WnhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-MLEybJFAMNvXCzYw95mJT3BlbkFJz9e3O8NhaQ6bx6t1zD4U\"\n","openai.api_key = os.environ[\"OPENAI_API_KEY\"]"],"metadata":{"id":"VaLiZD6yWrKn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data Setup¶\n","\n","Here, we first down load the PDF that we will use to generate training data."],"metadata":{"id":"sEVKOLf8mdOG"}},{"cell_type":"code","source":["!curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C20c8n4lWyX4","executionInfo":{"status":"ok","timestamp":1729070210377,"user_tz":-180,"elapsed":55002,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"e6550df1-d0d9-468a-ad22-06f72094e30f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 20.7M  100 20.7M    0     0   389k      0  0:00:54  0:00:54 --:--:--  431k\n"]}]},{"cell_type":"markdown","source":["\n","The next step is generating a training and eval dataset.\n","\n","We will generate 40 questions on different sections of the PDF we downloaded.\n","\n","We can use GPT-3.5 on the eval questions to get our baseline performance.\n","\n","Then, we will use GPT-4 on the train questions to generate our training data. The training data will be collected with out OpenAIFineTuningHandler.\n","\n","This step is entirely optional if you don't want to spend the time/tokens -- the eval and training questions are also provided in this folder, as well as the training data!"],"metadata":{"id":"v9miOyAbmh4s"}},{"cell_type":"code","source":["!pip install llama-index pypdf sentence-transformers ragas --quiet"],"metadata":{"id":"JKSpsr1hXED7","executionInfo":{"status":"ok","timestamp":1729070226021,"user_tz":-180,"elapsed":15850,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8693699-76eb-4a77-cfe1-69c1a507b51e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.8/173.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n","pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import nest_asyncio\n","\n","nest_asyncio.apply()"],"metadata":{"id":"EotXFLN_XrKw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train Generation"],"metadata":{"id":"IRvtcP5wml9u"}},{"cell_type":"code","source":["from llama_index.core import SimpleDirectoryReader\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core.evaluation import DatasetGenerator\n","\n","documents = SimpleDirectoryReader(\n","    input_files=[\"IPCC_AR6_WGII_Chapter03.pdf\"]\n",").load_data()\n","\n","# Shuffle the documents\n","import random\n","\n","random.seed(42)\n","random.shuffle(documents)\n","\n","gpt_35_llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)"],"metadata":{"id":"98_iWvznW2LF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question_gen_query = (\n","    \"You are a Teacher/ Professor. Your task is to setup \"\n","    \"a quiz/examination. Using the provided context, formulate \"\n","    \"a single question that captures an important fact from the \"\n","    \"context. Restrict the question to the context information provided.\"\n",")\n","\n","dataset_generator = DatasetGenerator.from_documents(\n","    documents[:50],\n","    question_gen_query=question_gen_query,\n","    llm=gpt_35_llm,\n",")"],"metadata":{"id":"FoHiW7H9Xel_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729070302588,"user_tz":-180,"elapsed":14015,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"9301272f-9434-4be3-9add-2c6dc5702be3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/llama_index/core/evaluation/dataset_generation.py:200: DeprecationWarning: Call to deprecated class DatasetGenerator. (Deprecated in favor of `RagDatasetGenerator` which should be used instead.)\n","  return cls(\n"]}]},{"cell_type":"code","source":["# NOTE: this may take some time. Go grab a coffee!\n","questions = dataset_generator.generate_questions_from_nodes(num=40)\n","print(\"Generated \", len(questions), \" questions\")"],"metadata":{"id":"S_CNnumSXkns","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729070306286,"user_tz":-180,"elapsed":3712,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"8b1bc66f-0152-4768-aa2b-2f0867aa0d83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated  40  questions\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/llama_index/core/evaluation/dataset_generation.py:296: DeprecationWarning: Call to deprecated class QueryResponseDataset. (Deprecated in favor of `LabelledRagDataset` which should be used instead.)\n","  return QueryResponseDataset(queries=queries, responses=responses_dict)\n"]}]},{"cell_type":"code","source":["with open(\"train_questions.txt\", \"w\") as f:\n","    for question in questions:\n","        f.write(question + \"\\n\")"],"metadata":{"id":"6Ope_FcvX4q1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Eval Generation¶\n","\n","Now, lets generate questions on a completely different set of documents, in order to create our eval dataset."],"metadata":{"id":"a4Zt86lxX81k"}},{"cell_type":"code","source":["dataset_generator = DatasetGenerator.from_documents(\n","    documents[\n","        50:\n","    ],  # since we generated ~1 question for 40 documents, we can skip the first 40\n","    question_gen_query=question_gen_query,\n","    llm=gpt_35_llm,\n",")"],"metadata":{"id":"u3Lgk6yuX9_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729070309036,"user_tz":-180,"elapsed":2803,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"a0c97967-40e0-4bd6-df9f-444bb45cc249"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n","/usr/local/lib/python3.10/dist-packages/llama_index/core/evaluation/dataset_generation.py:200: DeprecationWarning: Call to deprecated class DatasetGenerator. (Deprecated in favor of `RagDatasetGenerator` which should be used instead.)\n","  return cls(\n"]}]},{"cell_type":"code","source":["# NOTE: this may take some time. Go grab a coffee!\n","questions = dataset_generator.generate_questions_from_nodes(num=40)\n","print(\"Generated \", len(questions), \" questions\")"],"metadata":{"id":"kdWohLIuYDLq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729070311337,"user_tz":-180,"elapsed":2350,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"a53b3eaa-ae8d-4070-a396-6db86215323b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated  40  questions\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/llama_index/core/evaluation/dataset_generation.py:296: DeprecationWarning: Call to deprecated class QueryResponseDataset. (Deprecated in favor of `LabelledRagDataset` which should be used instead.)\n","  return QueryResponseDataset(queries=queries, responses=responses_dict)\n"]}]},{"cell_type":"code","source":["with open(\"eval_questions.txt\", \"w\") as f:\n","    for question in questions:\n","        f.write(question + \"\\n\")"],"metadata":{"id":"g7WXIujsYFhy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Initial Eval with GPT-3.5-Turbo Query Engine¶\n","\n","For this eval, we will be using the [ragas evaluation library](https://github.com/explodinggradients/ragas).\n","\n","Ragas has a ton of evaluation metrics for RAG pipelines, and you can read about them [here](https://docs.ragas.io/en/stable/).\n","\n","For this notebook, we will be using the following two metrics\n","\n","- answer_relevancy - This measures how relevant is the generated answer to the prompt. If the generated answer is incomplete or contains redundant information the score will be low. This is quantified by working out the chance of an LLM generating the given question using the generated answer. Values range (0,1), higher the better.\n","- faithfulness - This measures the factual consistency of the generated answer against the given context. This is done using a multi step paradigm that includes creation of statements from the generated answer followed by verifying each of these statements against the context. The answer is scaled to (0,1) range. Higher the better."],"metadata":{"id":"QIMGHNvxYJaE"}},{"cell_type":"code","source":["questions = []\n","with open(\"eval_questions.txt\", \"r\") as f:\n","    for line in f:\n","        questions.append(line.strip())"],"metadata":{"id":"Ec7VtsJQYMZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import VectorStoreIndex\n","\n","# limit the context window to 2048 tokens so that refine is used\n","from llama_index.core import Settings\n","\n","Settings.context_window = 2048\n","\n","index = VectorStoreIndex.from_documents(\n","    documents,\n",")\n","\n","query_engine = index.as_query_engine(similarity_top_k=2, llm=gpt_35_llm)"],"metadata":{"id":"SLBSuF0EYRJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["contexts = []\n","answers = []\n","\n","for question in questions:\n","    response = query_engine.query(question)\n","    contexts.append([x.node.get_content() for x in response.source_nodes])\n","    answers.append(str(response))"],"metadata":{"id":"Srhc5UlUYWLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","from ragas import evaluate\n","from ragas.metrics import answer_relevancy, faithfulness\n","\n","ds = Dataset.from_dict(\n","    {\n","        \"question\": questions,\n","        \"answer\": answers,\n","        \"contexts\": contexts,\n","    }\n",")\n","\n","result = evaluate(ds, [answer_relevancy, faithfulness])\n","print(result)"],"metadata":{"id":"7UrA72DZYwWD","colab":{"base_uri":"https://localhost:8080/","height":222,"referenced_widgets":["e844840cdac74e3388db1028f49b23b9","f1eb10f8e58c4e32aec33a45547e2837","f56ba7096aa74006ba862e3a2f2edcff","4d228e64f1b2419ead446f187c900a62","9b3e743a92d944ceb9af6acbcaf6fee9","43134d41cba24998bfa4fd0c34689d73","e157da152a6c4f119dfa5be3501abb5a","407516a969cc452abf1b1e8d45f594c9","8d4ca89797df42e4aabcbe4075e200d9","8f64f55d6b92447cbafe9e6e3cc42019","63c23240314d42c2a69fcd0b0ed8f2e4"]},"executionInfo":{"status":"ok","timestamp":1729070528872,"user_tz":-180,"elapsed":98154,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"cdbb0847-44ed-4219-ad9f-54c7d7dbcacc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ragas/prompt/base.py:9: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  from ragas.llms.prompt import PromptValue\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e844840cdac74e3388db1028f49b23b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n"]},{"output_type":"stream","name":"stdout","text":["{'answer_relevancy': 0.9141, 'faithfulness': 0.9224}\n"]}]},{"cell_type":"markdown","source":["GPT-4 to Collect Training Data\n","\n","Here, we use GPT-4 and the OpenAIFineTuningHandler to collect data that we want to train on."],"metadata":{"id":"a0ahUdn-ZcOM"}},{"cell_type":"code","source":["from llama_index.llms.openai import OpenAI\n","from llama_index.finetuning.callbacks import OpenAIFineTuningHandler\n","from llama_index.core.callbacks import CallbackManager\n","\n","finetuning_handler = OpenAIFineTuningHandler()\n","callback_manager = CallbackManager([finetuning_handler])\n","\n","llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n","llm.callback_manager = callback_manager"],"metadata":{"id":"7_9caqEmZfHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions = []\n","with open(\"train_questions.txt\", \"r\") as f:\n","    for line in f:\n","        questions.append(line.strip())"],"metadata":{"id":"MZIAUyniZi6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import VectorStoreIndex\n","\n","index = VectorStoreIndex.from_documents(\n","    documents,\n",")\n","\n","query_engine = index.as_query_engine(similarity_top_k=2, llm=llm)"],"metadata":{"id":"ukf9SLFmZl3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for question in questions:\n","    response = query_engine.query(question)"],"metadata":{"id":"UQuSvRm-ZqVl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create OpenAIFinetuneEngine\n","\n","We create an OpenAIFinetuneEngine: the finetune engine will take care of launching a finetuning job, and returning an LLM model that you can directly plugin to the rest of LlamaIndex workflows.\n","\n","We use the default constructor, but we can also directly pass in our finetuning_handler into this engine with the from_finetuning_handler class method."],"metadata":{"id":"TQ4mnCnXaAcw"}},{"cell_type":"code","source":["print(f\"Number of events captured: {len(finetuning_handler._finetuning_events)}\")\n","print(f\"Events: {finetuning_handler._finetuning_events}\")\n","finetuning_handler.save_finetuning_events(\"finetuning_events.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEvpjhmnqsSC","executionInfo":{"status":"ok","timestamp":1729071077308,"user_tz":-180,"elapsed":348,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"6f9f0713-8529-4ff5-936a-5079e9dec8c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of events captured: 0\n","Events: {}\n","Wrote 0 examples to finetuning_events.jsonl\n"]}]},{"cell_type":"code","source":["finetuning_handler.save_finetuning_events(\"finetuning_events.jsonl\")"],"metadata":{"id":"uqFj9Nx8aDBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729070634172,"user_tz":-180,"elapsed":49,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"52de00cc-bb34-4fc8-96f5-e226d59f4e4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote 0 examples to finetuning_events.jsonl\n"]}]},{"cell_type":"markdown","source":["In case 0 examples are written or we will not wish to use GPT-4 on the train questions to generate our training data and save time/tokens, please collect and upload the above file from:  [github repo](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/finetuning/finetuning_events.jsonl)"],"metadata":{"id":"8hW5E1qvc_fV"}},{"cell_type":"code","source":["from llama_index.finetuning import OpenAIFinetuneEngine\n","\n","finetune_engine = OpenAIFinetuneEngine(\n","    \"gpt-3.5-turbo\",\n","    \"finetuning_events.jsonl\",\n","    # start_job_id=\"\"  # if you have an existing job, can specify id here\n",")\n"],"metadata":{"id":"sjFWjEvEaIEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["finetune_engine.finetune()"],"metadata":{"id":"1wO7RBz6aMjk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729071880248,"user_tz":-180,"elapsed":2565,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"cca2b203-c4a1-4d9e-ff9b-268dfc1cb81b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples: 61\n","First example:\n","{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}\n","{'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 410\\nfile_name: IPCC_AR6_WGII_Chapter03.pdf\\n\\nIt is challenging to apply this experimental approach to communities or ecosystems (see Figure \\nBox\\xa03.1.1).To date, most research on community or ecosystem response to climate-induced drivers has been in large-volume (>10,000 l) \\nmesocosms (Riebesell and Gattuso, 2014), or at natural analogues such as CO 2 seeps, in which only one driver (ocean acidification) is \\naltered (see (4) in Figure Box\\xa03.1.1).Only very recently have two drivers been incorporated into climate-change manipulation studies \\nexamining responses of primary producers to secondary consumers (see (5) in Figure Box\\xa03.1.1a; Nagelkerken et\\xa0al., 2020).Therefore, \\n‘natural experiments’ from the geological past (Reddin et\\xa0al., 2020) provide insights into how food webs and their constituents respond to \\ncomplex change involving multiple drivers.Contemporary observations are occasionally long enough (>50\\xa0years) to capture community \\nresponses to complex climate change.For example, Brun et\\xa0al.(2019) reported a shift in zooplankton community structure in the North \\nAtlantic (1960–2014), with major biogeochemical ramifications.Conducting sufficiently long manipulation experiments to study the effect of adaptation on organisms is equally difficult (see Figure \\nBox\\xa03.1.1b), with much research restricted to multi-year studies of the microevolution of fast-growing (more than one division per day) \\nphytoplankton species responding to single drivers (Lohbeck et\\xa0al., 2012; Schaum et\\xa0al., 2016).In a few experimental evolution studies \\n(see (7) in Figure Box\\xa03.1.1a; Brennan et\\xa0al., 2017), multiple drivers have been used, but none have used communities or ecosystems (see \\nFigure Box\\xa03.1.1b).Nevertheless, the fossil record provides limited evidence of adaptations to less rapid (relative to present day) climate \\nchange (Jackson et\\xa0al., 2018).Despite the need to explore ecological or biogeochemical responses to projected future ocean conditions, \\nlogistical challenges require that assessments of climate-change impacts at scales larger than mesocosms use large-scale, long-term in \\nsitu observational studies (as documented in Section\\xa03.4).\\n\\npage_label: 409\\nfile_name: IPCC_AR6_WGII_Chapter03.pdf\\n\\n3\\n409Oceans and Coastal Ecosystems and Their Services  Chapter 3\\nunderlies inhibited thermal adaptation under nitrogen-limited \\nconditions (low confidence) (Aranguren-Gassis et\\xa0 al., 2019).When \\nselection is strong due to unfavourable environmental conditions, \\nmicrobial populations can encounter functional and evolutionary \\ntrade-offs evidenced by reducing growth rates while increasing \\ntolerance and metabolism of reactive oxygen species (Lindberg and \\nCollins, 2020).Other trade-offs can be observed in offspring quality \\nand number (Lindberg and Collins, 2020).These findings contribute \\ntowards a mechanistic framework describing the range of evolutionary \\nstrategies in response to multiple drivers (Collins et\\xa0al., 2020), but other \\nhazards, such as extreme events (e.g., MHWs), still need to be included \\nbecause their characteristics may alter the potential for adaptation of \\nspecies and populations to climate change (Gruber et\\xa0al., 2021).3.3.5 Ecological Response to Multiple Drivers\\nAssessing ecological responses to multiple climate-induced drivers \\nrequires a combination of approaches, including laboratory- and \\nfield-based experiments, field observations (e.g., natural gradients, \\nclimate analogues), study of paleo-analogues and the development \\nof mechanistic and empirical models (Clapham, 2019; Gissi et\\xa0 al., \\n2021).Experimental studies of food-web responses are often limited \\nto an individual driver, although recent manipulations have used a \\nmatrix of >1000-l mesocosms to explore ecological responses to both \\nwarming and acidification (see Box\\xa0 3.1; Nagelkerken et\\xa0 al., 2020).Hence, complementary approaches are needed to indirectly explore \\nthe mechanisms underlying ecosystem responses to global climate \\nchange (Parmesan et\\xa0al., 2013).Observations from time series longer \\nthan modes of natural variability (i.e., decades) are essential for \\nrevealing and attributing ecological responses to climate change (e.g., \\nSection\\xa03.4; Barton et\\xa0al., 2015b; Brun et\\xa0al., 2019).Also, paleorecords \\nprovide insights into the influence of multiple drivers on marine \\nbiota (Cross-Chapter Box\\xa0 PALEO in Chapter\\xa0 1; Reddin et\\xa0 al., 2020).Specifically, associations between vulnerabilities and traits of marine \\nectotherms in laboratory experiments correspond with organismal \\nresponses to ancient hyperthermal events (medium confidence) \\n(Reddin et\\xa0 al., 2020).This corroboration suggests that responses to \\nmultiple drivers inferred from the fossil record can help provide insights \\ninto the future status of functional groups, and hence food webs, under \\nrapid climate change.Multi-species and integrated end-to-end ecosystem models are \\npowerful tools to explore and project outcomes to the often-interacting \\ncumulative effects of climate change and other anthropogenic drivers \\n(Section\\xa03.1; Kaplan and Marshall, 2016; Koenigstein et\\xa0al., 2016; Peck \\nand Pinnegar, 2018; Tittensor et\\xa0 al., 2018; Gissi et\\xa0 al., 2021).These \\nmodels can integrate some aspects of the knowledge accrued from \\nmanipulation experiments, paleo- and contemporary observations, help \\ntest the relative importance of specific drivers and driver combinations, \\nand identify synergistic or antagonistic responses (Koenigstein et\\xa0al., \\n2016; Payne et\\xa0al., 2016; Skogen et\\xa0al., 2018; Tittensor et\\xa0al., 2018).As these models are associated with wide-ranging uncertainties \\n(SM3.2.2; Payne et\\xa0 al., 2016; Trolle et\\xa0 al., 2019; Heneghan et\\xa0 al., \\n2021), they cannot be expected to accurately project the trajectories \\nof complex marine ecosystems under climate change; hence, they are \\nmost useful for assessing overall trends and in particular for providing a plausible envelope of trajectories across a range of assumptions \\n(Fulton et\\xa0al., 2018; Peck et\\xa0al., 2018; Tittensor et\\xa0al., 2018).\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What are some approaches used to assess ecological responses to multiple climate-induced drivers in the context of climate change and the oceans?\\nAnswer: '}\n","{'role': 'assistant', 'content': 'Several approaches are used to assess ecological responses to multiple climate-induced drivers. These include laboratory- and field-based experiments, field observations such as natural gradients and climate analogues, the study of paleo-analogues, and the development of mechanistic and empirical models. Experimental studies often focus on individual drivers, but recent manipulations have used large-volume mesocosms to explore ecological responses to both warming and acidification. Observations from time series longer than modes of natural variability are essential for revealing and attributing ecological responses to climate change. Paleorecords also provide insights into the influence of multiple drivers on marine biota. Multi-species and integrated end-to-end ecosystem models are powerful tools to explore and project outcomes to the often-interacting cumulative effects of climate change and other anthropogenic drivers. These models can integrate some aspects of the knowledge accrued from manipulation experiments, paleo- and contemporary observations, help test the relative importance of specific drivers and driver combinations, and identify synergistic or antagonistic responses.'}\n","No errors found\n","Num examples missing system message: 21\n","Num examples missing user message: 0\n","\n","#### Distribution of num_messages_per_example:\n","min / max: 2, 3\n","mean / median: 2.6557377049180326, 3.0\n","p5 / p95: 2.0, 3.0\n","\n","#### Distribution of num_total_tokens_per_example:\n","min / max: 229, 2011\n","mean / median: 1274.27868852459, 1385.0\n","p5 / p95: 533.0, 1848.0\n","\n","#### Distribution of num_assistant_tokens_per_example:\n","min / max: 11, 334\n","mean / median: 72.36065573770492, 37.0\n","p5 / p95: 23.0, 193.0\n","\n","0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n","Dataset has ~77731 tokens that will be charged for during training\n","By default, you'll train for 3 epochs on this dataset\n","By default, you'll be charged for ~233193 tokens\n","As of August 22, 2023, fine-tuning gpt-3.5-turbo is $0.008 / 1K Tokens.\n","This means your total cost for training will be $0.621848 per epoch.\n"]}]},{"cell_type":"code","source":["finetune_engine.get_current_job()"],"metadata":{"id":"QMxPoZDpdnld","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729072111635,"user_tz":-180,"elapsed":778,"user":{"displayName":"Eleni Verteouri","userId":"07245117832466595780"}},"outputId":"3c46b077-ddd1-435e-82ed-3912038b84ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FineTuningJob(id='ftjob-FoZijNDFjcr5bQbOnR7GUIMW', created_at=1729071879, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-im9sGhF83hIvhqEUvyw4IRS7', result_files=[], seed=1785037869, status='running', trained_tokens=None, training_file='file-98VjsAXhroEyMMzaINaFdnAd', validation_file=None, estimated_finish=1729072266, integrations=[], user_provided_suffix=None)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["ft_llm = finetune_engine.get_finetuned_model(temperature=0.3)"],"metadata":{"id":"opTMxWjXdtnH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluation\n","\n","After some time, your model will be done training!\n","\n","The next step is running our fine-tuned model on our eval dataset again to measure any performance increase."],"metadata":{"id":"YdOH_5OEgKSF"}},{"cell_type":"code","source":["from llama_index.llms.openai import OpenAI\n","from llama_index.finetuning.callbacks import OpenAIFineTuningHandler\n","from llama_index.core.callbacks import CallbackManager\n","\n","\n","# Option 1: pass in ft_llm directly into Settings\n","from llama_index.core import Settings\n","\n","Settings.llm = ft_llm\n","Settings.context_window = (\n","    2048  # limit the context window artifically to test refine process\n",")\n","\n","# # Option 2: you can also specify the model name manually\n","# ft_model_name = \"ft:gpt-3.5-turbo-0613:...\"\n","# Settings.llm = OpenAI(model=ft_model_name, temperature=0.3)"],"metadata":{"id":"e6zF232BgNK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions = []\n","with open(\"eval_questions.txt\", \"r\") as f:\n","    for line in f:\n","        questions.append(line.strip())"],"metadata":{"id":"6LrFhMiQgRZf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import VectorStoreIndex\n","\n","index = VectorStoreIndex.from_documents(documents)\n","\n","query_engine = index.as_query_engine(similarity_top_k=2, llm=ft_llm)"],"metadata":{"id":"87vpQPb9gV1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["contexts = []\n","answers = []\n","\n","for question in questions:\n","    response = query_engine.query(question)\n","    contexts.append([x.node.get_content() for x in response.source_nodes])\n","    answers.append(str(response))"],"metadata":{"id":"T5rCJhyAgaKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","from ragas import evaluate\n","from ragas.metrics import answer_relevancy, faithfulness\n","\n","ds = Dataset.from_dict(\n","    {\n","        \"question\": questions,\n","        \"answer\": answers,\n","        \"contexts\": contexts,\n","    }\n",")\n","\n","result = evaluate(ds, [answer_relevancy, faithfulness])\n","print(result)"],"metadata":{"id":"cNJwgrE7gzAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exploring Differences\n","\n","Let's quickly compare the differences in responses, to demonstrate that fine tuning did indeed change something."],"metadata":{"id":"-88Neo9zjPhf"}},{"cell_type":"code","source":["from llama_index.core import VectorStoreIndex\n","\n","index = VectorStoreIndex.from_documents(documents)"],"metadata":{"id":"bbnhx_lhjOIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions = []\n","with open(\"eval_questions.txt\", \"r\") as f:\n","    for line in f:\n","        questions.append(line.strip())"],"metadata":{"id":"L1od7LrjjXzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(questions[9])"],"metadata":{"id":"wQ9ZGVI6jaLw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Original"],"metadata":{"id":"KilhjXsZjcY8"}},{"cell_type":"code","source":["from llama_index.core.response.notebook_utils import display_response\n","from llama_index.llms.openai import OpenAI\n","\n","\n","gpt_35_llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)"],"metadata":{"id":"5gFmiw_EjdYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query_engine = index.as_query_engine(llm=gpt_35_llm)\n","\n","response = query_engine.query(questions[9])\n","\n","display_response(response)"],"metadata":{"id":"ym4nTxksjgPv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finetuned"],"metadata":{"id":"tkqLLWUplWjd"}},{"cell_type":"code","source":["query_engine = index.as_query_engine(llm=ft_llm)\n","\n","response = query_engine.query(questions[9])\n","\n","display_response(response)"],"metadata":{"id":"RtS2OdrclYod"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","As we can see, the fine-tuned model provides a more thorough response! This lines up with the increased faithfullness score from ragas, since the answer is more representative of the retrieved context."],"metadata":{"id":"v0Al853Vnn0V"}},{"cell_type":"markdown","source":["\n","So, in conclusion, finetuning with only ~61 questions actually helped improve our eval scores!\n","\n","answer_relevancy: 0.9385 -> 0.8188\n","\n","The answer relevancy dips slightly but it's small.\n","\n","faithfulness: 0.7568 -> 0.9151\n","\n","The faithfulness appears to have been improved! This mains the anwers given better fuffil the original question that was asked."],"metadata":{"id":"A-BF58NemG5Z"}}]}